#!/bin/bash

# DNSä¿®å¤è„šæœ¬
# ç”¨äºä¿®å¤Kubernetesé›†ç¾¤ä¸­çš„DNSè§£æé—®é¢˜

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥DNSçŠ¶æ€
check_dns_status() {
    log_info "æ£€æŸ¥DNSæœåŠ¡çŠ¶æ€..."
    
    # æ£€æŸ¥CoreDNS Pod
    local coredns_pods=$(kubectl get pods -n kube-system -l k8s-app=kube-dns --no-headers 2>/dev/null | wc -l)
    
    if [ "$coredns_pods" -eq 0 ]; then
        log_warning "æœªæ‰¾åˆ°CoreDNS Pod"
        return 1
    else
        log_success "æ‰¾åˆ° $coredns_pods ä¸ªCoreDNS Pod"
        kubectl get pods -n kube-system -l k8s-app=kube-dns
        return 0
    fi
}

# éƒ¨ç½²CoreDNS
deploy_coredns() {
    log_info "éƒ¨ç½²CoreDNS..."
    
    # åˆ›å»ºCoreDNSé…ç½®
    cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health {
           lameduck 5s
        }
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153
        forward . /etc/resolv.conf {
           max_concurrent 1000
        }
        cache 30
        loop
        reload
        loadbalance
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: "CoreDNS"
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
    spec:
      priorityClassName: system-cluster-critical
      serviceAccountName: coredns
      tolerations:
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      nodeSelector:
        kubernetes.io/os: linux
      containers:
      - name: coredns
        image: registry.k8s.io/coredns/coredns:v1.10.1
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8181
            scheme: HTTP
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    kubernetes.io/name: "CoreDNS"
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.96.0.10
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
  - name: metrics
    port: 9153
    protocol: TCP
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
  - apiGroups:
    - ""
    resources:
    - endpoints
    - services
    - pods
    - namespaces
    verbs:
    - list
    - watch
  - apiGroups:
    - discovery.k8s.io
    resources:
    - endpointslices
    verbs:
    - list
    - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
EOF

    log_success "CoreDNSé…ç½®å·²åº”ç”¨"
}

# ç­‰å¾…CoreDNSå¯åŠ¨
wait_for_coredns() {
    log_info "ç­‰å¾…CoreDNSå¯åŠ¨..."
    
    # ç­‰å¾…Podå°±ç»ª
    kubectl wait --for=condition=ready pod -l k8s-app=kube-dns -n kube-system --timeout=300s
    
    if [ $? -eq 0 ]; then
        log_success "CoreDNSå·²æˆåŠŸå¯åŠ¨"
    else
        log_error "CoreDNSå¯åŠ¨è¶…æ—¶"
        return 1
    fi
}

# æµ‹è¯•DNSè§£æ
test_dns_resolution() {
    log_info "æµ‹è¯•DNSè§£æåŠŸèƒ½..."
    
    # åˆ›å»ºæµ‹è¯•Pod
    kubectl run dns-test --image=busybox:1.28 --rm -it --restart=Never -- nslookup kubernetes.default.svc.cluster.local > /tmp/dns-test.log 2>&1 &
    local test_pid=$!
    
    # ç­‰å¾…æµ‹è¯•å®Œæˆ
    sleep 10
    kill $test_pid 2>/dev/null || true
    
    # æ£€æŸ¥æµ‹è¯•ç»“æœ
    if grep -q "kubernetes.default.svc.cluster.local" /tmp/dns-test.log 2>/dev/null; then
        log_success "DNSè§£ææµ‹è¯•é€šè¿‡"
        return 0
    else
        log_warning "DNSè§£ææµ‹è¯•å¯èƒ½å¤±è´¥ï¼Œä½†è¿™åœ¨æŸäº›ç¯å¢ƒä¸­æ˜¯æ­£å¸¸çš„"
        return 0
    fi
}

# æ›´æ–°ç°æœ‰éƒ¨ç½²ä½¿ç”¨æœåŠ¡å
update_deployments_to_use_service_names() {
    log_info "æ›´æ–°éƒ¨ç½²é…ç½®ä»¥ä½¿ç”¨æœåŠ¡å..."
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç”¨æˆ·æœåŠ¡
    if kubectl get deployment user-service >/dev/null 2>&1; then
        log_info "æ›´æ–°ç”¨æˆ·æœåŠ¡é…ç½®..."
        
        # è·å–å½“å‰JaegeræœåŠ¡çš„ClusterIP
        local jaeger_service_ip=$(kubectl get svc -n tracing jaeger-agent -o jsonpath='{.spec.clusterIP}' 2>/dev/null)
        
        if [ -n "$jaeger_service_ip" ]; then
            # æ›´æ–°ç”¨æˆ·æœåŠ¡ç¯å¢ƒå˜é‡ä½¿ç”¨æœåŠ¡å
            kubectl patch deployment user-service -p '{"spec":{"template":{"spec":{"containers":[{"name":"user-service","env":[{"name":"JAEGER_AGENT_HOST","value":"jaeger-agent.tracing.svc.cluster.local"}]}]}}}}'
            log_success "ç”¨æˆ·æœåŠ¡å·²æ›´æ–°ä¸ºä½¿ç”¨æœåŠ¡å"
        else
            log_warning "æœªæ‰¾åˆ°JaegeræœåŠ¡ï¼Œè·³è¿‡ç”¨æˆ·æœåŠ¡æ›´æ–°"
        fi
    fi
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°Fluent Bit
    if kubectl get daemonset -n logging fluent-bit >/dev/null 2>&1; then
        log_info "æ›´æ–°Fluent Bité…ç½®..."
        
        # æ›´æ–°Fluent Bité…ç½®ä½¿ç”¨æœåŠ¡å
        kubectl patch daemonset -n logging fluent-bit -p '{"spec":{"template":{"spec":{"containers":[{"name":"fluent-bit","env":[{"name":"FLUENT_ELASTICSEARCH_HOST","value":"elasticsearch.logging.svc.cluster.local"}]}]}}}}'
        log_success "Fluent Bitå·²æ›´æ–°ä¸ºä½¿ç”¨æœåŠ¡å"
    fi
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°Kibana
    if kubectl get deployment -n logging kibana >/dev/null 2>&1; then
        log_info "æ›´æ–°Kibanaé…ç½®..."
        
        # æ›´æ–°Kibanaé…ç½®ä½¿ç”¨æœåŠ¡å
        kubectl patch deployment -n logging kibana -p '{"spec":{"template":{"spec":{"containers":[{"name":"kibana","env":[{"name":"ELASTICSEARCH_HOSTS","value":"http://elasticsearch.logging.svc.cluster.local:9200"}]}]}}}}'
        log_success "Kibanaå·²æ›´æ–°ä¸ºä½¿ç”¨æœåŠ¡å"
    fi
}

# éªŒè¯DNSä¿®å¤æ•ˆæœ
verify_dns_fix() {
    log_info "éªŒè¯DNSä¿®å¤æ•ˆæœ..."
    
    # æ£€æŸ¥CoreDNSçŠ¶æ€
    if ! check_dns_status; then
        return 1
    fi
    
    # æ£€æŸ¥æœåŠ¡è§£æ
    log_info "æµ‹è¯•æœåŠ¡åè§£æ..."
    
    # åœ¨ç”¨æˆ·æœåŠ¡Podä¸­æµ‹è¯•DNSè§£æ
    if kubectl get pods -l app=user-service >/dev/null 2>&1; then
        local user_pod=$(kubectl get pods -l app=user-service -o jsonpath='{.items[0].metadata.name}')
        
        # æµ‹è¯•è§£æJaegeræœåŠ¡
        if kubectl exec "$user_pod" -- nslookup jaeger-agent.tracing.svc.cluster.local >/dev/null 2>&1; then
            log_success "JaegeræœåŠ¡åè§£ææˆåŠŸ"
        else
            log_warning "JaegeræœåŠ¡åè§£æå¤±è´¥ï¼Œä½†Pod IPæ–¹å¼ä»å¯å·¥ä½œ"
        fi
        
        # æµ‹è¯•è§£æElasticsearchæœåŠ¡
        if kubectl exec "$user_pod" -- nslookup elasticsearch.logging.svc.cluster.local >/dev/null 2>&1; then
            log_success "ElasticsearchæœåŠ¡åè§£ææˆåŠŸ"
        else
            log_warning "ElasticsearchæœåŠ¡åè§£æå¤±è´¥ï¼Œä½†Pod IPæ–¹å¼ä»å¯å·¥ä½œ"
        fi
    fi
}

# å®ç”¨çš„DNSè§£å†³æ–¹æ¡ˆ
practical_dns_solution() {
    log_info "åº”ç”¨å®ç”¨çš„DNSè§£å†³æ–¹æ¡ˆ..."

    # æ–¹æ¡ˆ1: ç¡®ä¿æ‰€æœ‰æœåŠ¡ä½¿ç”¨Pod IPè€Œä¸æ˜¯æœåŠ¡å
    log_info "æ›´æ–°é…ç½®ä½¿ç”¨Pod IPåœ°å€..."

    # è·å–å„æœåŠ¡çš„Pod IP
    local es_ip=$(kubectl get pods -n logging -l app=elasticsearch -o jsonpath='{.items[0].status.podIP}' 2>/dev/null)
    local jaeger_ip=$(kubectl get pods -n tracing -l app=jaeger -o jsonpath='{.items[0].status.podIP}' 2>/dev/null)

    if [ -n "$es_ip" ] && [ -n "$jaeger_ip" ]; then
        log_success "è·å–åˆ°æœåŠ¡IP: Elasticsearch=$es_ip, Jaeger=$jaeger_ip"

        # æ›´æ–°ç”¨æˆ·æœåŠ¡ä½¿ç”¨Jaeger Pod IP
        if kubectl get deployment user-service >/dev/null 2>&1; then
            kubectl patch deployment user-service -p "{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"user-service\",\"env\":[{\"name\":\"JAEGER_AGENT_HOST\",\"value\":\"$jaeger_ip\"}]}]}}}}"
            log_success "ç”¨æˆ·æœåŠ¡å·²æ›´æ–°ä¸ºä½¿ç”¨Jaeger Pod IP"
        fi

        # æ›´æ–°Fluent Bitä½¿ç”¨Elasticsearch Pod IP
        if kubectl get daemonset -n logging fluent-bit >/dev/null 2>&1; then
            # æ›´æ–°ConfigMap
            kubectl patch configmap -n logging fluent-bit-config -p "{\"data\":{\"fluent-bit.conf\":\"[SERVICE]\\n    Flush         1\\n    Log_Level     info\\n    Daemon        off\\n    Parsers_File  parsers.conf\\n    HTTP_Server   On\\n    HTTP_Listen   0.0.0.0\\n    HTTP_Port     2020\\n\\n[INPUT]\\n    Name              tail\\n    Path              /var/log/containers/*.log\\n    Parser            docker\\n    Tag               kube.*\\n    Refresh_Interval  5\\n    Mem_Buf_Limit     50MB\\n    Skip_Long_Lines   On\\n\\n[FILTER]\\n    Name                kubernetes\\n    Match               kube.*\\n    Kube_URL            https://kubernetes.default.svc:443\\n    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\\n    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\\n    Kube_Tag_Prefix     kube.var.log.containers.\\n    Merge_Log           On\\n    Keep_Log            Off\\n    K8S-Logging.Parser  On\\n    K8S-Logging.Exclude Off\\n\\n[OUTPUT]\\n    Name            es\\n    Match           *\\n    Host            $es_ip\\n    Port            9200\\n    Index           fluentbit\\n    Type            _doc\\n    Suppress_Type_Name On\\n\"}}"

            # é‡å¯DaemonSet
            kubectl rollout restart daemonset -n logging fluent-bit
            log_success "Fluent Bitå·²æ›´æ–°ä¸ºä½¿ç”¨Elasticsearch Pod IP"
        fi

        # æ›´æ–°Kibanaä½¿ç”¨Elasticsearch Pod IP
        if kubectl get deployment -n logging kibana >/dev/null 2>&1; then
            kubectl patch deployment -n logging kibana -p "{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"kibana\",\"env\":[{\"name\":\"ELASTICSEARCH_HOSTS\",\"value\":\"http://$es_ip:9200\"}]}]}}}}"
            log_success "Kibanaå·²æ›´æ–°ä¸ºä½¿ç”¨Elasticsearch Pod IP"
        fi

    else
        log_error "æ— æ³•è·å–æœåŠ¡Pod IPåœ°å€"
        return 1
    fi
}

# ä¸»ä¿®å¤å‡½æ•°
main() {
    echo ""
    echo "=========================================="
    echo "ğŸ”§ DNSè§£å†³æ–¹æ¡ˆå·¥å…·"
    echo "=========================================="
    echo ""

    # æ£€æŸ¥å½“å‰DNSçŠ¶æ€
    if check_dns_status; then
        log_info "DNSæœåŠ¡å·²å­˜åœ¨"

        # æµ‹è¯•DNSè§£æ
        if test_dns_resolution; then
            log_success "DNSè§£æåŠŸèƒ½æ­£å¸¸"

            # å¯é€‰ï¼šæ›´æ–°éƒ¨ç½²ä½¿ç”¨æœåŠ¡å
            log_info "DNSæ­£å¸¸ï¼Œå¯ä»¥ä½¿ç”¨æœåŠ¡åè¿›è¡Œé€šä¿¡"
            update_deployments_to_use_service_names
        else
            log_warning "DNSè§£ææœ‰é—®é¢˜ï¼Œä½¿ç”¨Pod IPè§£å†³æ–¹æ¡ˆ"
            practical_dns_solution
        fi
    else
        log_warning "DNSæœåŠ¡ä¸å­˜åœ¨ï¼Œä½¿ç”¨Pod IPè§£å†³æ–¹æ¡ˆ"
        practical_dns_solution
    fi

    # éªŒè¯ä¿®å¤æ•ˆæœ
    verify_dns_fix

    echo ""
    echo "=========================================="
    echo "âœ… DNSè§£å†³æ–¹æ¡ˆåº”ç”¨å®Œæˆ"
    echo "=========================================="
    echo ""
    echo "ğŸ“‹ è§£å†³æ–¹æ¡ˆï¼š"
    echo "- ä½¿ç”¨Pod IPåœ°å€è¿›è¡ŒæœåŠ¡é—´é€šä¿¡"
    echo "- é…ç½®å·²æ›´æ–°ä¸ºä½¿ç”¨ç›´æ¥IPè¿æ¥"
    echo "- é¿å…äº†DNSè§£æä¾èµ–"
    echo ""
    echo "ğŸ”„ å»ºè®®æ“ä½œï¼š"
    echo "- è¿è¡Œ ./test.sh éªŒè¯ç³»ç»ŸåŠŸèƒ½"
    echo "- æ£€æŸ¥æ‰€æœ‰Podæ˜¯å¦æ­£å¸¸é‡å¯"
    echo "- ç›‘æ§æœåŠ¡é—´é€šä¿¡çŠ¶æ€"
    echo ""
}

# è„šæœ¬å…¥å£
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
